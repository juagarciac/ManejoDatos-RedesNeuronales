{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Función para poder utilizar la red neuronal para nuevos datos.\n",
    "\n",
    "Es necesario escalar y transformar los datos para que sean compatibles con la red neuronal es importante entonces utilizar el siguiente codigo y que los nuevos datos sigan la misma distribución de datos usados en la base de datos, sino generara errores y distorciones en la predicción"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import joblib\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "\n",
    "# Función para transformar una nueva fila o DataFrame de datos\n",
    "def preparar_nuevos_datos(df_nuevo: pd.DataFrame) -> pd.DataFrame:\n",
    "    \"\"\"\n",
    "    Recibe un DataFrame con al menos las mismas columnas que los datos originales\n",
    "    (ejemplo: 'home_ownership', 'purpose', 'earliest_cr_line', etc.).\n",
    "    Devuelve un DataFrame transformado y escalado, listo para ser ingresado al modelo.\n",
    "    \"\"\"\n",
    "    scaler = joblib.load(\"scaler.joblib\")\n",
    "    model_columns = joblib.load(\"model_columns.joblib\")\n",
    "    # Copiamos para no alterar el DataFrame original\n",
    "    df_nuevo = df_nuevo.copy()\n",
    "\n",
    "    # 1. Ajustar la columna 'home_ownership'\n",
    "    #   (Si existía la eliminación de valores no deseados, aquí simplemente los forzamos a un valor común)\n",
    "    df_nuevo.loc[df_nuevo['home_ownership'].isin(['OTHER', 'NONE', 'ANY']), 'home_ownership'] = 'OTHER'\n",
    "\n",
    "    # 2. Unificar varias categorías de 'purpose' en 'other'\n",
    "    purpose_columns = [\n",
    "        \"moving\", \"vacation\", \"house\", \"educational\", \"renewable_energy\",\n",
    "        \"wedding\", \"medical\", \"car\", \"small_business\", \"major_purchase\", \"other\"\n",
    "    ]\n",
    "    df_nuevo.loc[df_nuevo[\"purpose\"].isin(purpose_columns), \"purpose\"] = \"other\"\n",
    "\n",
    "    # 3. Manejo de la columna 'loan_status' (si existiera en el nuevo set, la ignoramos o la usamos)\n",
    "    #    Aquí, asumimos que la columna 'loan_status' ya no es necesaria para la predicción.\n",
    "    #    Igualar categorías con 'Charged Off' o 'Fully Paid' si fuera requerido, o eliminar la columna.\n",
    "    if 'loan_status' in df_nuevo.columns:\n",
    "        df_nuevo.drop('loan_status', axis=1, inplace=True, errors='ignore')\n",
    "\n",
    "    # 4. Creación de campo 'target' en caso de que se requiera, pero si es para predecir, normalmente no se utiliza.\n",
    "    #    df_nuevo['target'] = ...\n",
    "\n",
    "    # 5. Transformar 'earliest_cr_line' en año y mes\n",
    "    if 'earliest_cr_line' in df_nuevo.columns:\n",
    "        df_nuevo['earliest_cr_line'] = pd.to_datetime(df_nuevo['earliest_cr_line'], format='%b-%Y', errors='coerce')\n",
    "        df_nuevo['earliest_cr_year'] = df_nuevo['earliest_cr_line'].dt.year\n",
    "        df_nuevo['earliest_cr_month'] = df_nuevo['earliest_cr_line'].dt.month\n",
    "        df_nuevo.drop('earliest_cr_line', axis=1, inplace=True)\n",
    "\n",
    "    # 6. One-hot encoding para columnas tipo string\n",
    "    string_columns = df_nuevo.select_dtypes(include=['object']).columns.tolist()\n",
    "    df_nuevo = pd.get_dummies(df_nuevo, columns=string_columns, drop_first=False)\n",
    "\n",
    "    # 7. Asegurar que las columnas coincidan con las del modelo\n",
    "    #    (Por ejemplo, usar las mismas columnas que dEntrenamiento o dEntrenamiento_balanced)\n",
    "    #    Suponemos que 'columnas_modelo' es la lista exacta de columnas que espera el modelo.\n",
    "    columnas_modelo = [\n",
    "        col for col in model_columns if col != 'target'\n",
    "    ]\n",
    "    # Añadir columnas faltantes con valor 0\n",
    "    for col in columnas_modelo:\n",
    "        if col not in df_nuevo.columns:\n",
    "            df_nuevo[col] = 0\n",
    "    # Quitar columnas sobrantes que el modelo no use\n",
    "    df_nuevo = df_nuevo[columnas_modelo]\n",
    "\n",
    "    # 8. Aplicar el scaler (StandardScaler) ya entrenado\n",
    "    #    Queda en forma de array, pero lo devolvemos como DataFrame con las mismas columnas\n",
    "    data_escalada = scaler.transform(df_nuevo)\n",
    "    df_nuevo_escalado = pd.DataFrame(data_escalada, columns=columnas_modelo)\n",
    "\n",
    "    # Retornamos el DataFrame escalado con las columnas ajustadas\n",
    "    return df_nuevo_escalado"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Ejemplo de uso\n",
    "\n",
    "Un ejemplo de como usar la función importando el scaler y la red neuronal para nuevas predicciones"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2025-01-22 01:41:58.937628: E external/local_xla/xla/stream_executor/cuda/cuda_fft.cc:485] Unable to register cuFFT factory: Attempting to register factory for plugin cuFFT when one has already been registered\n",
      "2025-01-22 01:41:58.995048: E external/local_xla/xla/stream_executor/cuda/cuda_dnn.cc:8454] Unable to register cuDNN factory: Attempting to register factory for plugin cuDNN when one has already been registered\n",
      "2025-01-22 01:41:59.021624: E external/local_xla/xla/stream_executor/cuda/cuda_blas.cc:1452] Unable to register cuBLAS factory: Attempting to register factory for plugin cuBLAS when one has already been registered\n",
      "2025-01-22 01:41:59.216525: I tensorflow/core/platform/cpu_feature_guard.cc:210] This TensorFlow binary is optimized to use available CPU instructions in performance-critical operations.\n",
      "To enable the following instructions: AVX2 FMA, in other operations, rebuild TensorFlow with the appropriate compiler flags.\n",
      "2025-01-22 01:42:00.721103: W tensorflow/compiler/tf2tensorrt/utils/py_utils.cc:38] TF-TRT Warning: Could not find TensorRT\n",
      "WARNING: All log messages before absl::InitializeLog() is called are written to STDERR\n",
      "I0000 00:00:1737528122.231034  126655 cuda_executor.cc:1001] could not open file to read NUMA node: /sys/bus/pci/devices/0000:01:00.0/numa_node\n",
      "Your kernel may have been built without NUMA support.\n",
      "I0000 00:00:1737528122.998972  126655 cuda_executor.cc:1001] could not open file to read NUMA node: /sys/bus/pci/devices/0000:01:00.0/numa_node\n",
      "Your kernel may have been built without NUMA support.\n",
      "I0000 00:00:1737528122.999074  126655 cuda_executor.cc:1001] could not open file to read NUMA node: /sys/bus/pci/devices/0000:01:00.0/numa_node\n",
      "Your kernel may have been built without NUMA support.\n",
      "I0000 00:00:1737528123.001528  126655 cuda_executor.cc:1001] could not open file to read NUMA node: /sys/bus/pci/devices/0000:01:00.0/numa_node\n",
      "Your kernel may have been built without NUMA support.\n",
      "I0000 00:00:1737528123.001685  126655 cuda_executor.cc:1001] could not open file to read NUMA node: /sys/bus/pci/devices/0000:01:00.0/numa_node\n",
      "Your kernel may have been built without NUMA support.\n",
      "I0000 00:00:1737528123.001766  126655 cuda_executor.cc:1001] could not open file to read NUMA node: /sys/bus/pci/devices/0000:01:00.0/numa_node\n",
      "Your kernel may have been built without NUMA support.\n",
      "I0000 00:00:1737528123.267575  126655 cuda_executor.cc:1001] could not open file to read NUMA node: /sys/bus/pci/devices/0000:01:00.0/numa_node\n",
      "Your kernel may have been built without NUMA support.\n",
      "I0000 00:00:1737528123.267681  126655 cuda_executor.cc:1001] could not open file to read NUMA node: /sys/bus/pci/devices/0000:01:00.0/numa_node\n",
      "Your kernel may have been built without NUMA support.\n",
      "2025-01-22 01:42:03.267693: I tensorflow/core/common_runtime/gpu/gpu_device.cc:2112] Could not identify NUMA node of platform GPU id 0, defaulting to 0.  Your kernel may not have been built with NUMA support.\n",
      "I0000 00:00:1737528123.267752  126655 cuda_executor.cc:1001] could not open file to read NUMA node: /sys/bus/pci/devices/0000:01:00.0/numa_node\n",
      "Your kernel may have been built without NUMA support.\n",
      "2025-01-22 01:42:03.268009: I tensorflow/core/common_runtime/gpu/gpu_device.cc:2021] Created device /job:localhost/replica:0/task:0/device:GPU:0 with 2863 MB memory:  -> device: 0, name: NVIDIA GeForce GTX 1050, pci bus id: 0000:01:00.0, compute capability: 6.1\n",
      "WARNING:absl:Compiled the loaded model, but the compiled metrics have yet to be built. `model.compile_metrics` will be empty until you train or evaluate the model.\n",
      "WARNING: All log messages before absl::InitializeLog() is called are written to STDERR\n",
      "I0000 00:00:1737528124.581221  127834 service.cc:146] XLA service 0x7f9e74004a60 initialized for platform CUDA (this does not guarantee that XLA will be used). Devices:\n",
      "I0000 00:00:1737528124.581370  127834 service.cc:154]   StreamExecutor device (0): NVIDIA GeForce GTX 1050, Compute Capability 6.1\n",
      "2025-01-22 01:42:04.597733: I tensorflow/compiler/mlir/tensorflow/utils/dump_mlir_util.cc:268] disabling MLIR crash reproducer, set env var `MLIR_CRASH_REPRODUCER_DIRECTORY` to enable.\n",
      "2025-01-22 01:42:04.674087: I external/local_xla/xla/stream_executor/cuda/cuda_dnn.cc:531] Loaded cuDNN version 8907\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 593ms/step\n",
      "Probabilidad predicción: [[0.22547604]\n",
      " [0.2472183 ]\n",
      " [0.17304985]\n",
      " [0.17074163]]\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "I0000 00:00:1737528125.105821  127834 device_compiler.h:188] Compiled cluster using XLA!  This line is logged at most once for the lifetime of the process.\n"
     ]
    }
   ],
   "source": [
    "import pandas as pd\n",
    "df = pd.read_csv(\"Base_datos_Entrenamiento.csv\")\n",
    "from tensorflow.keras.models import load_model\n",
    "import joblib\n",
    "joblib.load(\"scaler.joblib\")\n",
    "modelo_cargado=load_model(\"best_model.h5\")\n",
    "probar=df[0:4]\n",
    "probar=preparar_nuevos_datos(probar)\n",
    "\n",
    "prob_pred = modelo_cargado.predict(probar)\n",
    "print(\"Probabilidad predicción:\", prob_pred)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "tf-wsl",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.19"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
